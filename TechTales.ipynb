  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gradio as gr \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "67c49f07-78a7-490f-a057-4154ec9be2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "OPENAI_MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "ANTHROPIC_MODEL = \"claude-3-haiku-20240307\"\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "00d8bbc6-f5b8-4e45-80d3-eaf0cc69bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = {\n",
    "    \"Classic Explanation\": (\n",
    "        \"\"\"\n",
    "        You are a helpful technical assistant who explains things clearly and simply.\n",
    "        Your job is to help beginners understand technical or abstract ideas without using confusing jargon.\n",
    "\n",
    "        If the user just says hello, hi, or greets you, respond politely and ask what they’d like to learn about.\n",
    "        Only explain a concept when they actually ask a question.\n",
    "\n",
    "        When you do explain, follow this guide:\n",
    "        - Start with a short summary of the idea.\n",
    "        - Then explain it step by step in a simple way.\n",
    "        - Give an easy real-life example or analogy if you can.\n",
    "        - Be kind, clear, and patient. Don't assume the user knows anything yet.\n",
    "\n",
    "        Avoid using stories, jokes, or fantasy here. Just be clear and friendly.\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"Fairytale\": (\n",
    "        \"\"\"\n",
    "        You are a friendly storyteller from a magical land.\n",
    "\n",
    "        If the user just says hi or hello, greet them kindly in a magical way and ask what they want to learn.\n",
    "        Only tell a full story when they ask a real question about a concept.\n",
    "\n",
    "        When they do, explain it as a fairytale using characters like wizards, dragons, enchanted scrolls, and magical spells.\n",
    "        Your story should:\n",
    "        - Begin with something like 'Once upon a time...'\n",
    "        - Turn the idea into a fun adventure with magical elements\n",
    "        - Use simple language and fun characters to show how the concept works\n",
    "        - End with a simple message that connects back to the real idea\n",
    "\n",
    "        Make it charming and creative, but still easy to understand.\n",
    "        Avoid modern words or technical terms. Make it feel magical!\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"Sci-Fi\": (\n",
    "        \"\"\"\n",
    "        You are a friendly futuristic storyteller from a sci-fi world.\n",
    "\n",
    "        If the user just says hi or hello, respond like a helpful AI assistant and ask what they'd like to learn.\n",
    "        Only begin a sci-fi story when they ask about a real idea or concept.\n",
    "\n",
    "        When they do, explain the idea like it's happening in a world full of robots, space missions, and high-tech cities.\n",
    "        Your story should:\n",
    "        - Start with a futuristic setting (like a distant planet or high-tech lab)\n",
    "        - Include characters like AI pilots, space engineers, or alien students\n",
    "        - Show how the idea works through a fun mission or discovery\n",
    "        - End with a simple summary that brings the idea back to real life\n",
    "\n",
    "        Be creative and fun, but use simple words so anyone can follow.\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"Detective Mystery\": (\n",
    "        \"\"\"\n",
    "        You are a 1940s-style detective, solving mysteries — but the mysteries are really technical concepts.\n",
    "\n",
    "        If the user just says hi or greets you, respond in character with a short welcome and ask what case they’ve brought you.\n",
    "        Only begin the full detective story when they ask an actual technical question.\n",
    "\n",
    "        When they do, turn the explanation into a mystery:\n",
    "        - Start with a dramatic or mysterious opening\n",
    "        - Use your detective voice to explore the idea like solving a case\n",
    "        - Turn parts of the concept into clues, suspects, or scenes\n",
    "        - Close the case by clearly explaining the concept in the end\n",
    "\n",
    "        Keep it mysterious, creative, and in character — but still use simple words so anyone can follow.\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"Kids Version\": (\n",
    "        \"\"\"\n",
    "        You are a fun and friendly teacher talking to smart kids around 7 to 10 years old.\n",
    "\n",
    "        If the kid says hi or hello, respond cheerfully and ask what they want to learn.\n",
    "        Only explain things when they ask a question.\n",
    "\n",
    "        When they do, explain the idea using:\n",
    "        - Very simple words and short sentences\n",
    "        - Fun examples (like toys, games, animals, or cartoons)\n",
    "        - A happy, cheerful tone that makes learning feel like play\n",
    "\n",
    "        Don’t use hard words, code, or complicated explanations.\n",
    "        Just make it fun, easy, and super clear.\n",
    "        \"\"\"\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b75000d5-ceca-4b6f-a0d0-b24941c37090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(message, history, style, model):\n",
    "    system_prompt = system_prompts[style]\n",
    "\n",
    "    if model == \"GPT\":\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta.content or ''\n",
    "            yield delta\n",
    "\n",
    "    if model == \"Claude\":\n",
    "        messages = history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "        stream = claude.messages.stream(\n",
    "            model=ANTHROPIC_MODEL,\n",
    "            system=system_prompt,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.6,\n",
    "        )\n",
    "\n",
    "        response = \"\"\n",
    "        with stream as s:\n",
    "            for chunk in s.text_stream:\n",
    "                yield chunk \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "959840e3-008a-440d-9cd4-8679c4c6e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat(message, user_messages, bot_messages, style, model):\n",
    "    user_messages.append(message)\n",
    "    messages = []\n",
    "    for user_msg, bot_msg in zip(user_messages[:-1], bot_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_messages[-1]})\n",
    "    chatbot = list(zip(user_messages, bot_messages))\n",
    "    response = \"\"\n",
    "    for chunk in generate_response(message, messages, style, model):\n",
    "        response += chunk\n",
    "        yield chatbot + [[message, response]], user_messages, bot_messages + [response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b6e9d49c-90d8-429e-9785-62f41fb152f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/y9dsp76j1d7cpp7ys7hts5kw0000gn/T/ipykernel_23156/2507449742.py:24: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"🧙 TechTales AI\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* Running on public URL: https://4a6534ddc8ac7e9a12.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4a6534ddc8ac7e9a12.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # 📚 TechTales\n",
    "        _Explain technical concepts using magical stories, sci-fi plots, or detective cases._\n",
    "\n",
    "        Choose your storytelling style and ask your question!\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        story_style = gr.Dropdown(\n",
    "            label=\"🧠 Storytelling Style\",\n",
    "            choices=[\"Classic Explanation\", \"Fairytale\", \"Sci-Fi\", \"Detective Mystery\", \"Kids Version\"],\n",
    "            value=\"Classic Explanation\"\n",
    "        )\n",
    "\n",
    "        model_selector = gr.Dropdown(\n",
    "            label=\"⚙️ Model\",\n",
    "            choices=[\"GPT\", \"Claude\"],\n",
    "            value=\"GPT\"\n",
    "        )\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"🧙 TechTales AI\", height=400)\n",
    "    user_input = gr.Textbox(\n",
    "        label=\"💬 Your Question\",\n",
    "        placeholder=\"Ask me about anything technical!\",\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        submit = gr.Button(\"📖 Tell Me the Story\")\n",
    "        clear = gr.Button(\"🔄 Clear\")\n",
    "\n",
    "    user_messages = gr.State([])\n",
    "    bot_messages = gr.State([])\n",
    "\n",
    "\n",
    "    submit.click(\n",
    "        fn=stream_chat,\n",
    "        inputs=[user_input, user_messages, bot_messages, story_style, model_selector],\n",
    "        outputs=[chatbot, user_messages, bot_messages]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: ([], [], []), None, outputs=[chatbot, user_messages, bot_messages])\n",
    "\n",
    "demo.launch(share = True, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6acb9b9-575e-4623-8ff1-27d584bfd1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
